{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Pre-processing and Training<a id='4_Pre-processing_and_Training'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Contents<a id='4.1_Contents'></a>\n",
    "* [4 Pre-Processing and Training Data](#4_Pre-Processing_and_Training_Data)\n",
    "  * [4.1 Contents](#4.1_Contents)\n",
    "  * [4.2 Introduction](#4.2_Introduction)\n",
    "  * [4.3 Imports](#4.3_Imports)\n",
    "  * [4.4 Loading the Data](#4.4_Loading_the_Data)\n",
    "  * [4.5 Extract Borrower Data](#4.5_Extract_Borrower_Data)\n",
    "  * [4.6 Splitting Indicator and Numerical Features](#4.6_Splitting_Indicator_and_Numerical_Features)\n",
    "  * [4.7 Creating Dummy Features and Scaling Numeric Data](#4.7_Creating_Dummy_Features_and_Scaling_Numeric_Data)\n",
    "  * [4.8 Train/Test Split](#4.8_Train/Test_Split)\n",
    "  * [4.9 Initial Not-Even-A-Model](#4.9_Initial_Not-Even-A-Model)\n",
    "  * [4.10 Metrics](#4.10_Metrics)\n",
    "      * [4.10.1.1R-squared, or coefficient of determination](#4.10.1_R-squared,_or_coefficient_of_determination)\n",
    "      * [4.10.2 Mean Absolute Error](#4.10.2_Mean_Absolute_Error)\n",
    "      * [4.10.3 Mean Squared Error](#4.10.3_Mean_Squared_Error)\n",
    "  * [4.11 Initial Model](#4.11_Initial_Model)\n",
    "  * [4.12 Pipelines](#4.11_Pipelines)\n",
    "      * [4.12.1 Define the pipeline](#4.12.2_Define_the_pipeline)\n",
    "      * [4.12.2 Fit the pipeline](#4.12.2_Fit_the_pipeline)\n",
    "      * [4.12.3 Make predictions on the train and test sets](#4.12.3_Make_predictions_on_the_train_and_test_sets)\n",
    "      * [4.12.4 Assess performance](#4.12.4_Assess_performance)\n",
    "  * [4.13 Summary](#4.13_Summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Introduction<a id='4.2_Introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll begin building machine learning models. Before even starting with learning a machine learning model, let's start by considering how useful the mean value is as a predictor. Think of the first model as a baseline performance comparitor for any subsequent model. We'll then build up the process of efficiently and robustly creating and assessing models against it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Imports<a id='4.3_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score, recall_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import __version__ as sklearn_version\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\daenj\\\\OneDrive\\\\Desktop\\\\Datasets\\\\Capstone 2021'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\daenj\\OneDrive\\Desktop\\Datasets\\Capstone 2021')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Loading the Data<a id='4.4_Loading_the_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to remove the numerical data and create a new data frame with only the object data types. This will be used later when creating dummy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_data.csv')\n",
    "data = data.drop(columns='Unnamed: 0')\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_data = data_df.select_dtypes(include = ['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Extracting Borrower Data<a id='4.5_Extracting_Borrower_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're splitting the borrowers based on whether they have payment issues or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_issues = data_df[data_df.TARGET == 1]\n",
    "no_issues = data_df[data_df.TARGET == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24825, 41)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_issues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282686, 41)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_issues.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Splitting Indicator and Numerical Features<a id='4.6_Splitting_Indicator_and_Numerical_Features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the indicator and numerical features are split from borrowers with a target of 1 and 0. (Payment issues and no payment issues) Since the object data types was extracted from the whole data set, we won't use the object variables created here, only the float variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_issues_float = payment_issues.select_dtypes(include = ['int', 'float'])\n",
    "payment_issues_object = payment_issues.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_issues_float = no_issues.select_dtypes(include = ['int', 'float'])\n",
    "no_issues_object = no_issues.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
      "       'REGION_POPULATION_RELATIVE', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION',\n",
      "       'DAYS_ID_PUBLISH', 'CNT_FAM_MEMBERS', 'DAYS_LAST_PHONE_CHANGE'],\n",
      "      dtype='object')\n",
      "Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
      "       'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
      "       'NAME_HOUSING_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE',\n",
      "       'DAYS_BIRTH_BINS', 'INCOME_VAL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(no_issues_float.columns)\n",
    "print(no_issues_object.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Creating Dummy Features<a id='4.7_Creating_Dummy_Features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create dummy features for our categorical data. We'll use the object variable created at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat([data_df.drop(object_data, axis=1), pd.get_dummies(object_data)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next step concatenates the float variables from both groups of borrowers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [no_issues_float, payment_issues_float]\n",
    "float_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307511 entries, 1 to 307509\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   AMT_INCOME_TOTAL            307511 non-null  float64\n",
      " 1   AMT_CREDIT                  307511 non-null  float64\n",
      " 2   AMT_ANNUITY                 307511 non-null  float64\n",
      " 3   AMT_GOODS_PRICE             307511 non-null  float64\n",
      " 4   REGION_POPULATION_RELATIVE  307511 non-null  float64\n",
      " 5   DAYS_EMPLOYED               307511 non-null  float64\n",
      " 6   DAYS_REGISTRATION           307511 non-null  float64\n",
      " 7   DAYS_ID_PUBLISH             307511 non-null  float64\n",
      " 8   CNT_FAM_MEMBERS             307511 non-null  float64\n",
      " 9   DAYS_LAST_PHONE_CHANGE      307511 non-null  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 25.8 MB\n"
     ]
    }
   ],
   "source": [
    "float_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Train/Test Split<a id='4.8_Train/Test_Split'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Train/Test split has 30% of the data on the test split. As stated earlier, our target is either a 1 or 0 for all of the borrowers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = float_data\n",
    "target = data_df['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size= 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((215257, 10), (92254, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((215257,), (92254,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Initial Not-Even-A-Model<a id='4.9_Initial_Not-Even-A-Model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good place to start is to see how good the mean is as a predictor. In this case, the value here is our best guess at correctly predicting whether the average borrower WILL have payment issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08122848502023162"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean = y_train.mean()\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08122849]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "dumb_reg.constant_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 Metrics<a id='4.10_Metrics'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.10.1 R-squared, or coefficient of determination<a id='4.10.1_R-squared,_or_coefficient_of_determination'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One measure is $R^2$, the coefficient of determination. This is a measure of the proportion of variance in the dependent variable (payment issues or not) that is predicted by our \"model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 6#\n",
    "#Calculate the R^2 as defined above\n",
    "def r_squared(y, ypred):\n",
    "    \"\"\"R-squared score.\n",
    "    \n",
    "    Calculate the R-squared, or coefficient of determination, of the input.\n",
    "    \n",
    "    Arguments:\n",
    "    y -- the observed values\n",
    "    ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    ybar = np.sum(y) / len(y) #yes, we could use np.mean(y)\n",
    "    sum_sq_tot = np.sum((y - ybar)**2) #total sum of squares error\n",
    "    sum_sq_res = np.sum((y - ypred)**2) #residual sum of squares error\n",
    "    R2 = 1.0 - sum_sq_res / sum_sq_tot\n",
    "    return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08122849, 0.08122849, 0.08122849, 0.08122849, 0.08122849])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred_ = train_mean * np.ones(len(y_train))\n",
    "y_tr_pred_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08122849, 0.08122849, 0.08122849, 0.08122849, 0.08122849])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "y_tr_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.787954817524586e-05"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred = train_mean * np.ones(len(y_test))\n",
    "r_squared(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.10.2 Mean Absolute Error<a id='4.10.2_Mean_Absolute_Error'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 7#\n",
    "#Calculate the MAE as defined above\n",
    "def mae(y, ypred):\n",
    "    \"\"\"Mean absolute error.\n",
    "    \n",
    "    Calculate the mean absolute error of the arguments\n",
    "\n",
    "    Arguments:\n",
    "    y -- the observed values\n",
    "    ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    abs_error = np.abs(y - ypred)\n",
    "    mae = np.mean(abs_error)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14926083648360142"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14786587570123505"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean absolute error is arguably the most intuitive of all the metrics. This essentially tells you that, on average, you could expect your predictions to be 15% more likely to be wrong if you guessed that the average borrower will have payment issues based on an average of known values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.10.3 Mean Squared Error<a id='4.10.3_Mean_Squared_Error'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 8#\n",
    "#Calculate the MSE as defined above\n",
    "def mse(y, ypred):\n",
    "    \"\"\"Mean square error.\n",
    "    \n",
    "    Calculate the mean square error of the arguments\n",
    "\n",
    "    Arguments:\n",
    "    y -- the observed values\n",
    "    ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    sq_error = (y - ypred)**2\n",
    "    mse = np.mean(sq_error)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07463041824157111"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07323545745987244"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27318568, 0.2706205 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt([mse(y_train, y_tr_pred), mse(y_test, y_te_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 Initial Models<a id='4.11_Initial_Models'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's briefly build a model that uses the median to impute missing values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMT_INCOME_TOTAL              144000.00000\n",
       "AMT_CREDIT                    513531.00000\n",
       "AMT_ANNUITY                    24907.50000\n",
       "AMT_GOODS_PRICE               450000.00000\n",
       "REGION_POPULATION_RELATIVE         0.01885\n",
       "DAYS_EMPLOYED                   2215.00000\n",
       "DAYS_REGISTRATION               4508.00000\n",
       "DAYS_ID_PUBLISH                 3255.00000\n",
       "CNT_FAM_MEMBERS                    2.00000\n",
       "DAYS_LAST_PHONE_CHANGE           758.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the values we'll use to fill in any missing values\n",
    "X_defaults_median = X_train.median()\n",
    "X_defaults_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_train.fillna(X_defaults_median)\n",
    "X_te = X_test.fillna(X_defaults_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_scaled = scaler.transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression().fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = lm.predict(X_tr_scaled)\n",
    "y_te_pred = lm.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.08840988613150458, -0.08644039852085639)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r^2 - train, test\n",
    "median_r2 = r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)\n",
    "median_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08122848502023162, 0.07956294578012878)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_mae = mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)\n",
    "median_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08122848502023162, 0.07956294578012878)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_mse = mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)\n",
    "median_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.12 Pipelines<a id='4.12_Pipelines'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the model built above to a model built by a pipeline. Will the results be different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.12.1 Define the pipeline<a id='4.12.1_Define_the_pipeline'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_all = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), \n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_regression, k='all'),\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipe_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(pipe_all, 'fit'), hasattr(pipe_all, 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.12.2 Fit the pipeline<a id='4.12.2_Fit_the_pipeline'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function f_regression at 0x0000020109D7E700>)),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.12.3 Making Predictions on Train and Test Sets<a id='4.12.2_Making_Predictions_on_Train_and_Test_Sets'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = pipe_all.predict(X_train)\n",
    "y_te_pred = pipe_all.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.12.4 Assess Performance<a id='4.12.4_Assess_Performance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.08840988613150458, -0.08644039852085639)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08122848502023162, 0.07956294578012878)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08122848502023162, 0.07956294578012878)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(pipe_all, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91877265, 0.91877265, 0.91877076, 0.91877076, 0.91877076])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cv_results['test_score']\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9187715149692501, 9.243249537556939e-07)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores), np.std(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92, 0.92])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((np.mean(cv_scores) - 2 * np.std(cv_scores), np.mean(cv_scores) + 2 * np.std(cv_scores)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.13 Summary<a id='4.13_Summary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline and the median-imputed model are virtually the same. Our cross-validation test states that our average prediction accuracy is at about 92%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
