{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Pre-processing and Training<a id='4_Pre-processing_and_Training'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Contents<a id='4.1_Contents'></a>\n",
    "* [4 Pre-Processing and Training Data](#4_Pre-Processing_and_Training_Data)\n",
    "  * [4.1 Contents](#4.1_Contents)\n",
    "  * [4.2 Introduction](#4.2_Introduction)\n",
    "  * [4.3 Imports](#4.3_Imports)\n",
    "  * [4.4 Loading the Data](#4.4_Loading_the_Data)\n",
    "  * [4.5 Extract Borrower Data](#4.5_Extract_Borrower_Data)\n",
    "  * [4.6 Splitting Indicator and Numerical Features](#4.6_Splitting_Indicator_and_Numerical_Features)\n",
    "  * [4.7 Creating Dummy Features and Scaling Numeric Data](#4.7_Creating_Dummy_Features_and_Scaling_Numeric_Data)\n",
    "  * [4.8 Train/Test Split](#4.8_Train/Test_Split)\n",
    "  * [4.9 Feature Correlation](#4.9_Feature_Correlation)\n",
    "  * [4.10 Building a Quick Logistic Regression Model](#4.10_Building_a_Quick_Logistic_Regression_Model)\n",
    "  * [4.11 Assess Performance](#4.11_Assess_Performance)\n",
    "  * [4.12 Summary](#4.12_Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Introduction<a id='4.2_Introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll begin building machine learning models. Before even starting with learning a machine learning model, let's start by considering how useful the mean value is as a predictor. Think of the first model as a baseline performance comparitor for any subsequent model. We'll then build up the process of efficiently and robustly creating and assessing models against it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Imports<a id='4.3_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score, recall_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\daenj\\\\OneDrive\\\\Desktop\\\\Datasets\\\\Capstone 2021'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\daenj\\OneDrive\\Desktop\\Datasets\\Capstone 2021')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Loading the Data<a id='4.4_Loading_the_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to remove the numerical data and create a new data frame with only the object data types. This will be used later when creating dummy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_data.csv')\n",
    "data = data.drop(columns='Unnamed: 0')\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_data = data.select_dtypes(include = ['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Extracting Borrower Data<a id='4.5_Extracting_Borrower_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're splitting the borrowers based on whether they have payment issues or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_issues = data[data.TARGET == 1]\n",
    "no_issues = data[data.TARGET == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24825, 41)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_issues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282686, 41)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_issues.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Splitting Indicator and Numerical Features<a id='4.6_Splitting_Indicator_and_Numerical_Features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the indicator and numerical features are split from borrowers with a target of 1 and 0. (Payment issues and no payment issues) Since the object data types was extracted from the whole data set, we won't use the object variables created here, only the float variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_issues_float = payment_issues.select_dtypes(include = ['int', 'float'])\n",
    "payment_issues_object = payment_issues.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_issues_float = no_issues.select_dtypes(include = ['int', 'float'])\n",
    "no_issues_object = no_issues.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
      "       'REGION_POPULATION_RELATIVE', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION',\n",
      "       'DAYS_ID_PUBLISH', 'CNT_FAM_MEMBERS', 'DAYS_LAST_PHONE_CHANGE'],\n",
      "      dtype='object')\n",
      "Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
      "       'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
      "       'NAME_HOUSING_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE',\n",
      "       'DAYS_BIRTH_BINS', 'INCOME_VAL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(no_issues_float.columns)\n",
    "print(no_issues_object.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Creating Dummy Features<a id='4.7_Creating_Dummy_Features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next step concatenates the float variables from both groups of borrowers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [no_issues_float, payment_issues_float]\n",
    "float_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create dummy features for our categorical data. We'll use the object variable created at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_data = pd.get_dummies(object_data, drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are concatenating the float data and the object data into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = pd.concat([float_data, object_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Train/Test Split<a id='4.8_Train/Test_Split'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Train/Test split has 30% of the data on the test split. As stated earlier, our target is either a 1 or 0 for all of the borrowers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    concat_data,\n",
    "    data['TARGET'],\n",
    "    test_size=0.3, \n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Feature Correlation<a id='4.9_Feature_Correlation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section deals with highly correlated features and their removal from the model. Features that have greater than a 95% correlation will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = concat_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(correlation_matrix .columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FLAG_OWN_REALTY_Y', 'FLAG_OWN_CAR_Y', 'NAME_CONTRACT_TYPE_Revolving loans', 'CODE_GENDER_M', 'AMT_GOODS_PRICE', 'ORGANIZATION_TYPE_XNA', 'NAME_INCOME_TYPE_Pensioner'}\n"
     ]
    }
   ],
   "source": [
    "#These are the features that will be dropped.\n",
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=correlated_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Building A Quick Logistic Regression Model<a id='4.10_Building_A_Quick_Logistic_Regression_Model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've built a quick linear regression model with an accompanying confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_defaults_median = X_train.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_train.fillna(X_defaults_median)\n",
    "X_te = X_test.fillna(X_defaults_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_scaled = scaler.transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression().fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = lm.predict(X_tr_scaled)\n",
    "y_te_pred = lm.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 Assess Performance<a id='4.11_Assess_Performance'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly assess the performance of various models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_te_pred) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix states that this model correctly predicted 84912 true positives and 2 false positives. There were 7340 false negatives and no true negatives. Let's take a look at the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     84914\n",
      "           1       0.00      0.00      0.00      7340\n",
      "\n",
      "    accuracy                           0.92     92254\n",
      "   macro avg       0.46      0.50      0.48     92254\n",
      "weighted avg       0.85      0.92      0.88     92254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_te_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision for this model sits at 92%. This tells us that out of the 84914 borrowers that were labeled, the proportion that were labeled correctly is 92%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results of a logistic regression model to other types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0      LogisticRegression            0.92           0.92       0.00    0.00   \n",
       "1    KNeighborsClassifier            0.92           0.91       0.17    0.02   \n",
       "3              GaussianNB            0.91           0.91       0.05    0.00   \n",
       "2  DecisionTreeClassifier            1.00           0.84       0.10    0.12   \n",
       "\n",
       "   F1 score  \n",
       "0      0.00  \n",
       "1      0.03  \n",
       "3      0.01  \n",
       "2      0.11  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ml_model(X_train,X_test, y_train, y_test):\n",
    "  MLA = [LogisticRegression(),KNeighborsClassifier(),DecisionTreeClassifier(),GaussianNB()]\n",
    "  MLA_columns = []\n",
    "  MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "  row_index = 0\n",
    "  for alg in MLA:\n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index,'Model Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(X_train, y_train), 2)\n",
    "    MLA_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(X_test, y_test), 2)\n",
    "    MLA_compare.loc[row_index, 'Precision'] = round(precision_score(y_test, predicted),2)\n",
    "    MLA_compare.loc[row_index, 'Recall'] = round(recall_score(y_test, predicted),2)\n",
    "    MLA_compare.loc[row_index, 'F1 score'] = round(f1_score(y_test, predicted),2)\n",
    "    row_index+=1\n",
    "  MLA_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \n",
    "  return MLA_compare  \n",
    "ml_model(X_train,X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train accuracy is above 90% for all the models. Test accuracy only goes down with the decision tree model. It falls from 100% train accuracy to 84%. The KNC model has the second largest precision percentage at 17%, and the decision tree model has a 10% precision. Out of the KNC, Gaussian, and decision tree models, the decision tree model has the highest recall and f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.12 Summary<a id='4.12_Summary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical and categorical features were split up into two different datasets. After creating dummy variables for the object data, a new, concatenated dataframe was created that included the float data and the object data with the dummy variables. A train/test split was created before investigating feature correlations. Features that were highly correlated (above 95%) were removed from the dataset before building the logistic regression model. A confusion matrix and classification report were created to assess the results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
